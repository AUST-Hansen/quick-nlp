{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.plots import *\n",
    "from torchtext.data import Field\n",
    "from fastai.lm_rnn import seq2seq_reg\n",
    "from quicknlp import SpacyTokenizer, print_batch, S2SModelData\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAPATH = \"dataset/translation\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  models  tmp  train  validation\r\n"
     ]
    }
   ],
   "source": [
    "!cd $DATAPATH; ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_TOKEN = \"<sos>\"\n",
    "EOS_TOKEN = \"<eos>\"\n",
    "fields = [\n",
    "    (\"english\", Field(init_token=INIT_TOKEN, eos_token=EOS_TOKEN, tokenize=SpacyTokenizer('en'), lower=True)),\n",
    "    (\"french\", Field(init_token=INIT_TOKEN, eos_token=EOS_TOKEN, tokenize=SpacyTokenizer('fr'), lower=True))\n",
    "\n",
    "]\n",
    "batch_size = 64\n",
    "data = S2SModelData.from_text_files(path=DATAPATH, fields=fields,\n",
    "                                    train=\"train\",\n",
    "                                    validation=\"validation\",\n",
    "                                    source_names=[\"english\", \"french\"],\n",
    "                                    target_names=[\"french\"],\n",
    "                                    bs= batch_size\n",
    "                                   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num tr batches: 4, num tr samples: 201\n",
      "num val batches: 4,num val samples: 201\n"
     ]
    }
   ],
   "source": [
    "print(f'num tr batches: {len(data.trn_dl)}, num tr samples: {len(data.trn_ds)}')\n",
    "print(f'num val batches: {len(data.val_dl)},num val samples: {len(data.val_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_size = 300\n",
    "nh = 1024\n",
    "nl = 3\n",
    "tnh = 512\n",
    "learner = data.get_model(emb_sz=emb_size,\n",
    "                         nhid=nh,\n",
    "                         nlayers=nl,\n",
    "                         bidir=True,\n",
    "                         max_iterations=30,\n",
    "                         att_nhid=tnh,\n",
    "                         attention=True\n",
    "                         )\n",
    "reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "clip = 0.3\n",
    "learner.reg_fn = reg_fn\n",
    "learner.clip = clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seq2SeqAttention(\n",
      "  (encoder): EmbeddingRNNEncoder(\n",
      "    (rnns): ModuleList(\n",
      "      (0): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(300, 512, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 512, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "      (2): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 150, dropout=0.3, bidirectional=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropouths): ModuleList(\n",
      "      (0): LockedDropout(\n",
      "      )\n",
      "      (1): LockedDropout(\n",
      "      )\n",
      "      (2): LockedDropout(\n",
      "      )\n",
      "    )\n",
      "    (encoder): Embedding(102, 300, padding_idx=1)\n",
      "    (encoder_with_dropout): EmbeddingDropout(\n",
      "      (embed): Embedding(102, 300, padding_idx=1)\n",
      "    )\n",
      "    (dropouti): LockedDropout(\n",
      "    )\n",
      "  )\n",
      "  (decoder): RNNAttentionDecoder(\n",
      "    (rnns): ModuleList(\n",
      "      (0): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(600, 1024, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "      (1): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 1024, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "      (2): Cell(\n",
      "        (cell): WeightDrop(\n",
      "          (module): LSTM(1024, 300, dropout=0.3)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (dropouths): ModuleList(\n",
      "      (0): LockedDropout(\n",
      "      )\n",
      "      (1): LockedDropout(\n",
      "      )\n",
      "      (2): LockedDropout(\n",
      "      )\n",
      "    )\n",
      "    (encoder): Embedding(209, 300, padding_idx=1)\n",
      "    (encoder_with_dropout): EmbeddingDropout(\n",
      "      (embed): Embedding(209, 300, padding_idx=1)\n",
      "    )\n",
      "    (dropouti): LockedDropout(\n",
      "    )\n",
      "    (projection_layer): AttentionProjection(\n",
      "      (attention): MLPAttention(\n",
      "        (linear1): Linear(in_features=600, out_features=512, bias=False)\n",
      "        (linear2): Linear(in_features=512, out_features=1, bias=False)\n",
      "      )\n",
      "      (projection1): Projection(\n",
      "        (linear): Linear(in_features=600, out_features=300, bias=False)\n",
      "        (dropout): LockedDropout(\n",
      "        )\n",
      "      )\n",
      "      (projection2): Projection(\n",
      "        (linear): Linear(in_features=300, out_features=209, bias=False)\n",
      "        (dropout): LockedDropout(\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "learner.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 sample : 0\n",
      "input: am i fat ?\n",
      "target: - je grosse ?\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n",
      "batch: 0 sample : 1\n",
      "input: am i fat ?\n",
      "target: - je gros ?\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n",
      "batch: 0 sample : 2\n",
      "input: ask tom .\n",
      "target: à tom .\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n",
      "batch: 0 sample : 3\n",
      "input: attack !\n",
      "target: !\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n",
      "batch: 0 sample : 4\n",
      "input: attack !\n",
      "target: !\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n",
      "batch: 0 sample : 5\n",
      "input: awesome !\n",
      "target:   !\n",
      "prediction: ['on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on on']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_batch(lr=learner,dt=data, input_field=\"english\", output_field=\"french\",num_sentences=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.lr_find()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
